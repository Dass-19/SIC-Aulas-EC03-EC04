{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f232c43d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset cargado exitosamente\n",
      "Dimensiones del dataset: (303, 14)\n",
      "\n",
      "EXPLORACIÓN INICIAL:\n",
      "Primeras 5 filas:\n",
      "    age  sex   cp  trestbps   chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
      "0  63.0  1.0  1.0     145.0  233.0  1.0      2.0    150.0    0.0      2.3   \n",
      "1  67.0  1.0  4.0     160.0  286.0  0.0      2.0    108.0    1.0      1.5   \n",
      "2  67.0  1.0  4.0     120.0  229.0  0.0      2.0    129.0    1.0      2.6   \n",
      "3  37.0  1.0  3.0     130.0  250.0  0.0      0.0    187.0    0.0      3.5   \n",
      "4  41.0  0.0  2.0     130.0  204.0  0.0      2.0    172.0    0.0      1.4   \n",
      "\n",
      "   slope   ca  thal  target  \n",
      "0    3.0  0.0   6.0       0  \n",
      "1    2.0  3.0   3.0       2  \n",
      "2    2.0  2.0   7.0       1  \n",
      "3    3.0  0.0   3.0       0  \n",
      "4    1.0  0.0   3.0       0  \n",
      "\n",
      "Información del dataset:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 303 entries, 0 to 302\n",
      "Data columns (total 14 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   age       303 non-null    float64\n",
      " 1   sex       303 non-null    float64\n",
      " 2   cp        303 non-null    float64\n",
      " 3   trestbps  303 non-null    float64\n",
      " 4   chol      303 non-null    float64\n",
      " 5   fbs       303 non-null    float64\n",
      " 6   restecg   303 non-null    float64\n",
      " 7   thalach   303 non-null    float64\n",
      " 8   exang     303 non-null    float64\n",
      " 9   oldpeak   303 non-null    float64\n",
      " 10  slope     303 non-null    float64\n",
      " 11  ca        299 non-null    float64\n",
      " 12  thal      301 non-null    float64\n",
      " 13  target    303 non-null    int64  \n",
      "dtypes: float64(13), int64(1)\n",
      "memory usage: 33.3 KB\n",
      "None\n",
      "\n",
      "Valores nulos por columna:\n",
      "age         0\n",
      "sex         0\n",
      "cp          0\n",
      "trestbps    0\n",
      "chol        0\n",
      "fbs         0\n",
      "restecg     0\n",
      "thalach     0\n",
      "exang       0\n",
      "oldpeak     0\n",
      "slope       0\n",
      "ca          4\n",
      "thal        2\n",
      "target      0\n",
      "dtype: int64\n",
      "Eliminando filas con valores nulos\n",
      "  Dataset después de limpieza: (297, 14)\n",
      "\n",
      "PREPROCESAMIENTO DE VARIABLE OBJETIVO:\n",
      "Valores únicos en target antes: [np.int64(0), np.int64(1), np.int64(2), np.int64(3), np.int64(4)]\n",
      "• Distribución de clases después de binarización:\n",
      "target_binary\n",
      "0    160\n",
      "1    137\n",
      "Name: count, dtype: int64\n",
      "   - 0: No enfermedad (160 muestras)\n",
      "   - 1: Enfermedad cardíaca (137 muestras)\n",
      "\n",
      "DIVISIÓN DE DATOS:\n",
      "Entrenamiento: 207 muestras\n",
      "Prueba: 90 muestras\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# pip install xgboost\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# PREPROCESAMIENTO Y CONVERSIÓN DE DATOS\n",
    " \n",
    "# URL del dataset de Enfermedad Cardíaca de Cleveland\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/processed.cleveland.data\"\n",
    "\n",
    "# Nombres de columnas según la documentación del dataset\n",
    "column_names = [\n",
    "    'age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg',\n",
    "    'thalach', 'exang', 'oldpeak', 'slope', 'ca', 'thal', 'target'\n",
    "]\n",
    "\n",
    "# Cargar el dataset\n",
    "try:\n",
    "    df = pd.read_csv(url, names=column_names, na_values='?')\n",
    "    print(\"Dataset cargado exitosamente\")\n",
    "except Exception as e:\n",
    "    print(f\"Error al cargar dataset: {e}\")\n",
    "    # Crear dataset de ejemplo para continuar el ejercicio\n",
    "    from sklearn.datasets import make_classification\n",
    "    X, y = make_classification(n_samples=303, n_features=13, random_state=42)\n",
    "    df = pd.DataFrame(X, columns=column_names[:-1])\n",
    "    df['target'] = y\n",
    "\n",
    "print(f\"Dimensiones del dataset: {df.shape}\")\n",
    "\n",
    "# Exploración inicial de los datos\n",
    "print(\"\\nEXPLORACIÓN INICIAL:\")\n",
    "print(f\"Primeras 5 filas:\")\n",
    "print(df.head())\n",
    "print(f\"\\nInformación del dataset:\")\n",
    "print(df.info())\n",
    "print(f\"\\nValores nulos por columna:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Manejar valores nulos (si existen)\n",
    "if df.isnull().sum().sum() > 0:\n",
    "    print(\"Eliminando filas con valores nulos\")\n",
    "    df = df.dropna()\n",
    "    print(f\"  Dataset después de limpieza: {df.shape}\")\n",
    "\n",
    "# Preprocesar la variable objetivo\n",
    "# La columna target original tiene valores 0-4, donde 0 = no enfermedad, 1-4 = enfermedad\n",
    "print(\"\\nPREPROCESAMIENTO DE VARIABLE OBJETIVO:\")\n",
    "print(f\"Valores únicos en target antes: {sorted(df['target'].unique())}\")\n",
    "\n",
    "# Convertir a problema binario: 0 = no enfermedad, 1 = enfermedad\n",
    "df['target_binary'] = (df['target'] > 0).astype(int)\n",
    "\n",
    "print(f\"• Distribución de clases después de binarización:\")\n",
    "print(df['target_binary'].value_counts())\n",
    "print(f\"   - 0: No enfermedad ({(df['target_binary'] == 0).sum()} muestras)\")\n",
    "print(f\"   - 1: Enfermedad cardíaca ({(df['target_binary'] == 1).sum()} muestras)\")\n",
    "\n",
    "# Preparar variables predictoras y objetivo\n",
    "X = df.drop(['target', 'target_binary'], axis=1)  \n",
    "y = df['target_binary']  # Target binario\n",
    "\n",
    "# Dividir en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.3,       \n",
    "    random_state=42,     \n",
    "    stratify=y          \n",
    ")\n",
    "\n",
    "print(f\"\\nDIVISIÓN DE DATOS:\")\n",
    "print(f\"Entrenamiento: {X_train.shape[0]} muestras\")\n",
    "print(f\"Prueba: {X_test.shape[0]} muestras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1b064ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. ÁRBOL DE DECISIÓN INDIVIDUAL\n",
      "Árbol de Decisión entrenado\n",
      "   • Precisión (Accuracy): 0.7333\n",
      "   • Profundidad del árbol: 9\n",
      "   • Número de hojas: 32\n",
      "\n",
      "2. RANDOM FOREST - BAGGING\n",
      "Random Forest entrenado\n",
      "   • Precisión (Accuracy): 0.8556\n",
      "   • Número de árboles: 100\n",
      "   • Características por split: sqrt\n",
      "\n",
      "3. XGBOOST - BOOSTING\n",
      "XGBoost entrenado\n",
      "   • Precisión (Accuracy): 0.8111\n",
      "   • Número de árboles (estimators): None\n"
     ]
    }
   ],
   "source": [
    "# ENTRENAMIENTO Y EVALUACIÓN DE MODELOS\n",
    "\n",
    "\n",
    "# Diccionario para almacenar resultados\n",
    "resultados = {}\n",
    "\n",
    "# MODELO 1: ÁRBOL DE DECISIÓN INDIVIDUAL\n",
    "print(\"\\n1. ÁRBOL DE DECISIÓN INDIVIDUAL\")\n",
    "\n",
    "\"\"\"\n",
    "**CARACTERÍSTICAS DEL ÁRBOL INDIVIDUAL:**\n",
    "• Aprece reglas if-else simples\n",
    "• Alta interpretabilidad\n",
    "• Propenso a sobreajuste (overfitting)\n",
    "• Alta varianza - sensible a pequeños cambios en datos\n",
    "\"\"\"\n",
    "\n",
    "tree_model = DecisionTreeClassifier(random_state=42)\n",
    "tree_model.fit(X_train, y_train)\n",
    "y_pred_tree = tree_model.predict(X_test)\n",
    "\n",
    "accuracy_tree = accuracy_score(y_test, y_pred_tree)\n",
    "resultados['Árbol Decisión'] = accuracy_tree\n",
    "\n",
    "print(f\"Árbol de Decisión entrenado\")\n",
    "print(f\"   • Precisión (Accuracy): {accuracy_tree:.4f}\")\n",
    "print(f\"   • Profundidad del árbol: {tree_model.get_depth()}\")\n",
    "print(f\"   • Número de hojas: {tree_model.get_n_leaves()}\")\n",
    "\n",
    "# MODELO 2: RANDOM FOREST (BAGGING)\n",
    "print(\"\\n2. RANDOM FOREST - BAGGING\")\n",
    "\n",
    "\"\"\"\n",
    "**CONCEPTO DE BAGGING (Bootstrap Aggregating):**\n",
    "\n",
    "• Entrena MÚLTIPLES árboles en PARALELO\n",
    "• Cada árbol ve un subconjunto aleatorio de datos (muestreo con reemplazo)\n",
    "• Cada árbol considera un subconjunto aleatorio de características\n",
    "• Combina resultados por VOTACIÓN MAYORITARIA\n",
    "\"\"\"\n",
    "\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "resultados['Random Forest'] = accuracy_rf\n",
    "\n",
    "print(f\"Random Forest entrenado\")\n",
    "print(f\"   • Precisión (Accuracy): {accuracy_rf:.4f}\")\n",
    "print(f\"   • Número de árboles: {len(rf_model.estimators_)}\")\n",
    "print(f\"   • Características por split: {rf_model.max_features}\")\n",
    "\n",
    "# MODELO 3: XGBOOST (BOOSTING)\n",
    "print(\"\\n3. XGBOOST - BOOSTING\")\n",
    "\n",
    "\"\"\"\n",
    "**CONCEPTO DE BOOSTING (Refuerzo Secuencial):**\n",
    "\n",
    "• Entrena árboles de forma SECUENCIAL (uno tras otro)\n",
    "• Cada nuevo árbol se enfoca en corregir errores del anterior\n",
    "• Asigna mayor peso a muestras mal clasificadas\n",
    "• Combina resultados por SUMA PONDERADA\n",
    "\"\"\"\n",
    "\n",
    "xgb_model = XGBClassifier(random_state=42, eval_metric='logloss')\n",
    "xgb_model.fit(X_train, y_train)\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "\n",
    "accuracy_xgb = accuracy_score(y_test, y_pred_xgb)\n",
    "resultados['XGBoost'] = accuracy_xgb\n",
    "\n",
    "print(f\"XGBoost entrenado\")\n",
    "print(f\"   • Precisión (Accuracy): {accuracy_xgb:.4f}\")\n",
    "print(f\"   • Número de árboles (estimators): {xgb_model.n_estimators}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
